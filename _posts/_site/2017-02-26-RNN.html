<h4 id="section">从神经网络谈起</h4>

<p>了解神经网络的都知道，神经网络作为一种非线性模型，在监督学习领域取得了state-of-art的效果，其中反向传播算法的提出居功至伟，到如今仍然是主流的优化神经网络参数的算法. 递归神经网络、卷积神经网络以及深度神经网络作为人工神经网络的”变种”，仍然延续了ANN的诸多特质，如权值连接，激励函数，以神经元为计算单元等，只不过因为应用场景的不同衍生了不同的特性，如：处理变长数据、权值共享等。</p>

<p>为了介绍RNN，先简单的介绍ANN. ANN的结构很容易理解，一般是三层结构（输入层-隐含层-输出层）. 隐含层输出<script type="math/tex">O_j</script> 和输出层输出<script type="math/tex">O_k</script>如下。其中<script type="math/tex">net_j</script>为隐含层第<script type="math/tex">j</script>个神经元的输入,<script type="math/tex">u</script>为输入层和隐含层的连接权值矩阵，<script type="math/tex">v</script>为隐含层和输出层之间的连接权值矩阵.</p>

<p><script type="math/tex">O_j=f(net_j)</script>
<script type="math/tex">O_k=f(net_k)</script>
<script type="math/tex">net_j=\sum_i(x_{i}*u_{i,j})+b_j</script>
<script type="math/tex">net_k=\sum_j(O_{j}*v_{j,k})+b_k</script></p>

<table>
  <tbody>
    <tr>
      <td>定义损失函数为 $$E=\sum_p\sum_k</td>
      <td> </td>
      <td>y_k^p-d_k^p</td>
      <td> </td>
      <td>^2<script type="math/tex">,其中</script>p<script type="math/tex">为样本下标，</script>y^p<script type="math/tex">为第</script>p<script type="math/tex">个样本的预测值,</script>d^p<script type="math/tex">为样本</script>p<script type="math/tex">的的真实值。然后分别对参数</script>v_{j,k}<script type="math/tex">、</script>u_{i,j}$$ 进行求导，可得：</td>
    </tr>
  </tbody>
</table>

<script type="math/tex; mode=display">\frac{\partial E}{\partial v_{j,k}} = \ 
 = df</script>

