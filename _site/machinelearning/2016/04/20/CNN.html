<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1" /> <title>卷积神经网络的一些小事儿</title> <meta name="twitter:card" content="summary" /> <meta name="twitter:site" content="@kymo" /> <meta name="twitter:title" content="卷积神经网络的一些小事儿" /> <meta name="twitter:description" content="1. 从手写体图片识别说起"> <meta name="description" content="1. 从手写体图片识别说起"> <link rel="icon" href="/assets/favicon.png"> <link rel="apple-touch-icon" href="/assets/touch-icon.png"> <link rel="stylesheet" href="//code.cdn.mozilla.net/fonts/fira.css"> <link rel="stylesheet" href="/assets/core.css"> <link rel="canonical" href="/machinelearning/2016/04/20/CNN.html"> <link rel="alternate" type="application/atom+xml" title="Aron blog" href="/feed.xml" /> <!-- mathjax config similar to math.stackexchange --> <script type="text/x-mathjax-config"> MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) }, tex2jax: { inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" }, TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } }, messageStyle: "none" }); </script> <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </head> <body> <aside class="logo"> <a href="/"> <img src="/public/image/avatar.jpg" class="gravatar"> </a> <span class="logo-prompt">Back to Home</span> </aside> <main> <noscript> <style> article .footnotes { display: block; } </style> </noscript> <article> <div style='float:left;'> <div class="center"> <h1>卷积神经网络的一些小事儿</h1> <time>April 20, 2016</time> </div> <div class="divider"></div> <h3 id="1-从手写体图片识别说起">1. 从手写体图片识别说起</h3> <p>手写体识别一般是神经网络入门必备的demo，在传统的神经网络进行手写体识别的时候，需要更多的人工对特征进行处理，一般是如下的步骤:</p> <blockquote> <p>1.将原始图片的像素值栅格化为一维向量,如原始图片为8*8, 则栅格化之后的向量为164; <br /> 2.将栅格化的向量作为神经网络的输入，手写体对应的数字编码之后作为神经网络的输出;</p> </blockquote> <p>然后在MNIST数据集上也能有96%以上的正确率，但是MNIST数据集给的都是28*28大小的数据，如果图片的像素规模很大呢？这里可能就会考虑两个方案：要么就是直接将全部的像素作为神经网络的输入；要么就是人工去对像素进行采样降维。那么可行性又如何？对于第一种，假设隐层神经元的数量为1000，那么输入层-隐含层权值矩阵就达到了$10^9$的规模，一般的机器根本训不动，更别提用梯度下降这种可能会陷入局部最优的算法了(参数多，解空间大)；对于第二种可能就是无尽的特征提取工作了。</p> <p>谈到第二点，深度学习某种意义可以认为是对特征的学习. 领域知识在传统机器学习中十分重要，不管是CTR预估亦或是信用评级、LTR等，都需要在相关领域有较多的经验，往往某几个特征的发现能够给整个系统带来质的飞跃，当然这也使得传统机器学习的解释性更好。</p> <h3 id="2-你的眼睛是怎么看图片的">2. 你的眼睛是怎么看图片的？</h3> <p>通常而言，我们在观察事物的时候，都是会将注意力集中到某一块部分，可能一块还足以让我们判断这个东西的类型，但是多观察几个局部，就能大概知道所观察的东西是个啥了。这个给我们的启发是对于输入的1000*1000像素的图片，我们并不需要所有像素的信息，提取局部的特征也能够给我们勾勒出该图片所代表的事物的特征。这个在卷积神经网络中对应的就是卷积核。另外，对图片进行采样模糊等变换，某种程度上也不会改变图片中事物的主要特征，这个在卷积神经网络中对应的就是pooling，也就是向下采样.</p> <h3 id="3-卷积神经网络">3. 卷积神经网络</h3> <p>那么卷积神经网络是如何处理类似于图片这种结构的输入呢？卷积神经网络中采用了两种十分有效的思路：局部感知和权值共享；前面提到如果直接将图像的像素作为神经网络的输入，需要学习的参数较多。表观上图像所代表的信息通过局部也能够表达，对于神经网络而言，虽然单个神经元只感受到了局部，但是整体的特征已经被整个模型所接收，最后的效果也不会差到哪里去，而随之带来的就是学习参数数目的下降。比如原始图像为1000*1000，隐层为1000000个节点，每个节点只与输入图像的5*5的区域相连，此时需要学习的参数为2.5*10^7，是原先的四万分之一.</p> <p>但是这些参数的学习仍然是一个不小的挑战，但是如果隐层节点与输入层区域相连的权值都一样呢，那样子需要学习的参数仅仅为25个，而这个25个参数一般也被称之为卷积核，也有叫滤波器的，总而言之就是对局部特征进行某种线性变换的参数！如此而来，用较小的参数规模实现了对图像局部特征的学习！单个的卷积核造成的问题就是特征提取不够充分，所以一般采用的都是多个卷积核，每种卷积核所体现的就是图像局部不同的特征！卷积过后，如果直接用这些特征进行分类，一是维度过大导致训练不便，二是有可能导致过拟合，所以一般在卷积之后会加一个对卷积层特征的聚合过程，也即Pooling层。</p> <p>表达卷积神经网络一般是卷积层与pooling层交替组合，构成深度神经网络，多层卷积能够组合局部特征从而表征全局，像下图中经典的LeNet-5网络结构，就是由3个卷积层和两个pooling层以及一个全连接层组成。</p> <p><img src="http://7pn4yt.com1.z0.glb.clouddn.com/blog-lenet.jpg" alt="" /></p> <p>卷积层和pooling层可以认为是对特征的学习过程，然后将学习到的特征再输入到一个分类器中进行训练. 在卷积层，是利用卷积核对上一层的特征图进行卷积操作，然后将卷积结果重新输出到新的特征图中，在LeNet5中的C1层中，利用的就是6个5*5的卷积核对输入图像进行卷积，然后得到6个特征图，每个特征图的大小是28*28.</p> <p>这里需要注意的是，卷积层的特征图并不仅仅是来自于前一层的一个特征图，有可能是前一层的多个特征图和多个卷积核进行联合操作之后得到，如LeNet-5中Pooling层S2到卷积层C3就是按照如下的排列进行连接的, 其中C3的第一个特征图来自于S2中的0,1,2号3个特征图，最后一个特征图与S2中的所有特征图相连，此时需要60个卷积核. 加上偏置，需要学习的参数为60*5*5+16. <br /> <img src="http://images2015.cnblogs.com/blog/743682/201604/743682-20160421101636460-1080820356.png" alt="" /></p> <h4 id="31-卷积层">3.1 卷积层</h4> <p>令$X_j^l$ 为第$l$层(卷积层)第j个特征图，当$l=1$时即为原始图像特征，$M_j^l$为与第$l$层(卷积层)第$j$个特征图相连的前一层特征图集合的某个子集，那么第l层的第j个特征图的计算：</p> <script type="math/tex; mode=display">X_j^l = f(\sum_{i\in M_j^l}K^l_{i,j}*X_i^{l-1} + b_j^l)</script> <p>其中，<script type="math/tex">*</script>为卷积运算，$b_j^l$为一维的实数，假设图片像素矩阵$P$，卷积核为$K$, 如下:</p> <p> $$ {\begin{matrix} P=\begin{bmatrix} 0 &amp; 1 &amp; 2 &amp; 2\\ 1 &amp; 0 &amp; 3 &amp; 3 \\ 3 &amp; 4 &amp; 3 &amp; 0 \\ 4 &amp; 2 &amp; 4 &amp; 4 \\ \end{bmatrix} &amp; K = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; -1 \end{bmatrix} \end{matrix}} $$ </p> <p>那么对图像进行卷积之后的结果$F=K*P$为：</p> <p> $$ F=\begin{bmatrix} 1 &amp; 7 &amp; 11 \\ 10 &amp; 13 &amp; 3 \\ 9 &amp; 9 &amp; 9 \\ \end{bmatrix} $$ </p> <p>此时需要注意卷积不是直接算矩阵点乘，而是将卷积矩阵旋转180度之后再算点乘。并且F中的元素与P中的元素有如下的对应关系，其中u,v为输出特征图的下标，卷积核大小为d*d，$K_{d-h,d-j}$为卷积核参数$K_{h,j}$旋转180度之后对应的值，$P_{u+h,v+j}$为与输入特征图进行卷积的位置的像素值。</p> <p> $$ F_{u,v} = \sum_{h}\sum_{j} K_{d-h,d-j}*P_{u+h,v+j} $$ </p> <p>卷积核的大小d一般选奇数，卷积时候的步长(一般为1)也可以根据具体的场景进行调整，当然如果为了保证卷积之后维度不变，也可以进行边缘扩展，在原始特征图的边缘补充新的像素值。</p> <h4 id="32-pooling层">3.2 Pooling层</h4> <p>Pooling层主要的作用是降噪降维，缓解过拟合的尴尬。为什么这么说呢？因为就典型的max pooling（取最大）或者averaging pooling(取平均)操作而言，它能够使得模型关注于局部某一部分，而不是具体的像素，模型的鲁棒性和泛化能力得到了一定程度的保障。</p> <p>Pooling层的特征图与上一层的卷积层一一对应，只不过特征图的维度变小。令$X_j^l$为Pooling层的第j个特征图，$down()$为向下采样。则有：</p> <script type="math/tex; mode=display">X_j^l = f(\beta_j^l \cdot down(X_j^{l-1}) + b_j^l)</script> <p>对于Pooling层的输入特征图，其每一个采样局部共享同一个采样尺度和偏置，也即$\beta_j^ll$和$b_j^l$都是一个实数. Pooling层之后，维度一般会减半。假设学习到的采样尺度为0.25, 偏执为0.1，采样窗口为2*2，激励函数f才用的sigmoid函数，则在Pooling层由输入特征图到输出特征图的过程如下：</p> <p> $$ {\begin{matrix} X_j^{l-1}=\begin{bmatrix} 0 &amp; 2 &amp; 4 &amp; 2\\ 2 &amp; 0 &amp; 3 &amp; 3 \\ 3 &amp; 4 &amp; 3 &amp; 0 \\ 4 &amp; 2 &amp; 4 &amp; 4 \\ \end{bmatrix} &amp; X_j^l = \begin{bmatrix} f(1.1) &amp; f(3.1) \\ f(3.35) &amp; f(2.85) \end{bmatrix} \end{matrix}} $$ </p> <h4 id="33-全连接层">3.3 全连接层</h4> <p>在通过卷积层和Pooling层可以认为是对特征的学习，在这个交替的层次之后，原始的数据被转换到新的特征空间中，然后通过全连接层将特征空间和样本空间进行关联。在通常情况下，全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为1x1的卷积；而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽。</p> <h4 id="34-反向传播推导">3.4 反向传播推导</h4> <p>CNN的推导和基本的全连接神经网络无异，没什么特别的地方，关键在于两点:</p> <blockquote> <p>1.卷积层到Pooling层，前向计算的时候由于下采样导致为维度降低，在误差反向传导时，需要对下一层误差进行反向采样 <br /> 2.Pooling层到卷积层，误差项中需要弄清楚和当前卷积核进行卷积的patch.</p> </blockquote> <p>令$\delta_j^l$ 为第$l$层第$j$个特征图$X_j^l$对应的误差项，其维度和$X_j^l$一致，$(\delta_j^l)_{u,v}$ 为$X_j^l$ 下标为u,v对应的误差项，即有：</p> <p> $$ \begin{align} \delta_j^l &amp; = \frac {\partial E}{\partial net_j^l} ; (\delta_j^l)_{u,v} = \frac {\partial E}{\partial ((net_j^l)_{u,v})} \\ net_j^l &amp;= \left\{ \begin{aligned} &amp; \sum_{i\in M_j^l}K^l_{i,j}*X_i^{l-1} + b_j^l \ \ \ l层为卷积层 \\ &amp; \beta_j^l \cdot down(X_j^{l-1}) + b_j^l \ \ \ l层为Pooling层\\ \end{aligned} \right. \end{align} $$ </p> <p><strong>当$l$层为卷积层时</strong>，需要学习的参数为卷积核和偏执，个数为$\sum_{j}{||M_j||} + N^l$，其中$||M_j||$为与卷积层第j个特征图相连的前层特征图的某个子集，$N^l$为第l层卷积层的特征图数目。</p> <p>每一个输出特征图对应一个为偏执$b_j^l$, 且$b_j^l$为标量，其与每一个$(\delta_j^l)_{u,v}$ 都有关联，所以对偏执的求导为：</p> <p> $$ \begin{align} \frac {\partial E}{\partial b_j^l} &amp; = \sum_u\sum_v \frac {\partial E}{\partial ((net_j^l)_{u,v})} \frac {\partial ((net_j^l)_{u,v})}{\partial b_j^l} = \sum_u\sum_v (\delta_j^l)_{u,v} \end{align} $$ </p> <p>每一个输出特征图由若干个卷积核与输入特征图卷积得来，对于卷积核$K_{i,j}^l$而言，其求导的结果为一个$d*d$的矩阵，对于其中的某个值$(K_{i,j})_{r,s}$求导为, 其中r,s为卷积核中的下标，大小在[0,d-1]范围内，u,v为输出特征图的下标：</p> <p> $$ \begin{align} \frac {\partial E}{\partial ((K_{i,j}^l)_{r,s})} &amp; = \sum_u\sum_v \frac {\partial E}{\partial ((net_j^l)_{u,v})} \frac {\partial ((net_j^l)_{u,v})}{\partial ((K_{i,j}^l)_{r,s})} \\ &amp; = \sum_u\sum_v (\delta_j^l)_{u,v}\frac {\partial ((net_j^l)_{u,v})}{\partial ((K_{i,j}^l)_{r,s})} \\ &amp; = \sum_u\sum_v (\delta_j^l)_{u,v}\frac {\partial ((X_i^{l-1} * K_{i,j}^l)_{u,v})}{\partial ((K_{i,j}^l)_{r,s})} \end{align} $$ </p> <p>此时又有：</p> <p> $$ (X_i^{l-1} * K_{i,j}^l)_{u,v} = \sum_{r}\sum_{s} (K_{i,j}^l)_{r,s}(X_i^{l-1})_{u+r,v+s} $$ </p> <p>所以：</p> <p> $$ \begin{align} \frac {\partial E}{\partial ((K_{i,j}^l)_{r,s})} &amp; = \sum_u\sum_v (\delta_j^l)_{u,v} (X_i^{l-1})_{u+r,v+s} \end{align} $$ </p> <p>也即：</p> <p> $$ \begin{align} \frac {\partial E}{\partial K_{i,j}^l} &amp; = \sum_u\sum_v (\delta_j^l)_{u,v} (PT_i^{l-1})_{u,v} \end{align} $$ </p> <p>其中，$PT_i^{l-1}$为$X_i^{l-1}$中与卷积核进行卷积的部分，可以认为是一个4维的矩阵，$(PT_i^{l-1})_{u,v}$对应于$X_i^{l-1}$中$row\in [u,u+d-1] \ \ col\in [v,v+d-1]$范围内的部分.</p> <p>卷积层的误差项来自于下一层与其相连的Pooling层，此时有:</p> <p> $$ \begin{align} \left\{ \begin{aligned} net_j^{l+1} &amp; = \beta_j^{l+1} \circ down(X_j^{l}) + b_j^{l+1} \\ X_j^{l} &amp; = f(net_j^l) \\ \end{aligned} \right. \end{align} $$ </p> <p>所以：</p> <p> $$ \begin{align} \frac {\partial E}{\partial net_j^l} &amp; = \frac {\partial E}{\partial net_j^{l+1}} \frac {\partial E}{\partial net_j^{l+1}} \end{align} $$ </p> <p><strong>当$l$层为Pooling层时</strong>，需要学习的参数为偏执和采样尺度，每一个特征图对应两个参数。对偏执的求导与卷积层无异，对采样尺度$\beta_j^l$的求导如下：</p> <p> $$ \begin{align} \frac {\partial E}{\partial \beta_j^l} &amp; = \sum_u\sum_v \frac {\partial E}{\partial ((net_j^l)_{u,v})} \frac {\partial ((net_j^l)_{u,v})}{\partial \beta_j^l} \\ &amp; = \sum_u\sum_v (\delta_j^l)_{u,v} down(X_j^{l-1})_{u,v} \\ &amp; = \sum_u\sum_v (\delta_j^l \circ down(X_j^{l-1}))_{u,v} \end{align} $$ </p> <h3 id="35-应用">3.5 应用</h3> <h3 id="参考文献">参考文献</h3> <p><a href="http://blog.csdn.net/xuanyuansen/article/details/41800721">卷积神经网络（一）：LeNet5的基本结构</a> <br /> <a href="http://blog.csdn.net/kaido0/article/details/53161684">理解结构，LeNet5介绍</a> <br /> <a href="http://dataunion.org/11692.html">技术向：一文读懂卷积神经网络CNN</a> <a href="https://www.zhihu.com/question/41037974">全连接层的作用是什么？</a></p> </div> <div id='article_list_p st' style='float:right; width:250px; height:100%; position:absolute; right:10px; top:300px; font-size:12px;'> </div> </article> <div class="ds-thread" data-thread-key="/machinelearning/2016/04/20/CNN" data-title="卷积神经网络的一些小事儿" data-url="//machinelearning/2016/04/20/CNN.html" style='width:766px;margin:0px auto'></div> <!-- 多说评论框 end --> <!-- 多说公共JS代码 start (一个网页只需插入一次) --> <script type="text/javascript"> var duoshuoQuery = {short_name:"aron"}; (function() { var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); })(); </script> <!-- 多说公共JS代码 end --> <div class="back"> <a href="/">Back</a> </div> </main> </body> </html>