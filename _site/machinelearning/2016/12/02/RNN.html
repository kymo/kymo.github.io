<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1" /> <title>RNN</title> <meta name="twitter:card" content="summary" /> <meta name="twitter:site" content="@kymo" /> <meta name="twitter:title" content="RNN" /> <meta name="twitter:description" content="从神经网络谈起"> <meta name="description" content="从神经网络谈起"> <link rel="icon" href="/assets/favicon.png"> <link rel="apple-touch-icon" href="/assets/touch-icon.png"> <link rel="stylesheet" href="//code.cdn.mozilla.net/fonts/fira.css"> <link rel="stylesheet" href="/assets/core.css"> <link rel="canonical" href="/machinelearning/2016/12/02/RNN.html"> <link rel="alternate" type="application/atom+xml" title="Aron's blog" href="/feed.xml" /> <!-- mathjax config similar to math.stackexchange --> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ extensions: ["tex2jax.js"], jax: ["input/TeX", "output/HTML-CSS"], tex2jax: { inlineMath: [ ['$', '$'] ], displayMath: [ ['$$', '$$']], processEscapes: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }, messageStyle: "none", "HTML-CSS": { preferredFont: "TeX", availableFonts: ["TeX"] } }); </script> <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </head> <body> <aside class="logo"> <a href="/"> <img src="/public/image/avatar.jpg" class="gravatar"> </a> <span class="logo-prompt">Back to Home</span> </aside> <main> <noscript> <style> article .footnotes { display: block; } </style> </noscript> <article> <div style='float:left;'> <div class="center"> <h1>RNN</h1> <time>December 2, 2016</time> </div> <div class="divider"></div> <h4 id="section">从神经网络谈起</h4> <p>了解神经网络的都知道，神经网络作为一种非线性模型，在监督学习领域取得了state-of-art的效果，其中反向传播算法的提出居功至伟，到如今仍然是主流的优化神经网络参数的算法. 递归神经网络、卷积神经网络以及深度神经网络作为人工神经网络的”变种”，仍然延续了ANN的诸多特质，如权值连接，激励函数，以神经元为计算单元等，只不过因为应用场景的不同衍生了不同的特性，如：处理变长数据、权值共享等。</p> <p>为了介绍RNN，先简单的介绍ANN. ANN的结构很容易理解，一般是三层结构（输入层-隐含层-输出层）. 隐含层输出<script type="math/tex">O_j</script> 和输出层输出<script type="math/tex">O_k</script>如下。其中<script type="math/tex">net_j</script>为隐含层第<script type="math/tex">j</script>个神经元的输入,<script type="math/tex">u</script>为输入层和隐含层的连接权值矩阵，<script type="math/tex">v</script>为隐含层和输出层之间的连接权值矩阵.</p> <p><script type="math/tex">O_j=f(net_j)</script> <script type="math/tex">O_k=f(net_k)</script> <script type="math/tex">net_j=\sum_i(x_{i}u_{i,j})+b_j</script> <script type="math/tex">net_k=\sum_j(O_{j}v_{j,k})+b_k</script></p> <p>定义损失函数为<script type="math/tex">E=\frac{1}{2}\sum_p\sum_k (O_k^p - d_k^p)^2</script> ,其中<script type="math/tex">p</script>为样本下标，<script type="math/tex">y^p</script>为第<script type="math/tex">p</script>个样本的预测值,<script type="math/tex">d^p</script>为样本<script type="math/tex">p</script>的的真实值。然后分别对参数<script type="math/tex">v_{j,k}</script>、<script type="math/tex">u_{i,j}</script> 进行求导，可得：</p> <script type="math/tex; mode=display">\frac{\partial E}{\partial v_{j,k}} = \frac{\partial E}{\partial net_k} \frac{\partial net_k}{\partial v_{j,k}} \\ = \frac{\partial E}{\partial net_k}O_j \\ = \frac{\partial E}{\partial O_k}\frac{\partial O_k}{\partial net_k}O_j \\ = \sum_p (O_k^p-d_k^p)f(net_k)(1-f(net_k))O_j</script> <script type="math/tex; mode=display">\frac{\partial E}{\partial net_k} = \\ = ni \\ = nhao \\</script> <script type="math/tex; mode=display">% <![CDATA[ \begin{array}{c|clr} n & \text{Left} & \text{Center} & \text{Right} \\ \hline 1 & 0.24 & 1 & 125 \\ 2 & -1 & 189 & -8 \\ 3 & -20 & 2000 & 1+10i \\ \end{array} %]]></script> </div> <div id='article_list_p st' style='float:right; width:250px; height:100%; position:absolute; right:10px; top:300px; font-size:12px;'> <h2>文章列表</h2></hr> <a href="/machinelearning/2016/12/02/RNN.html">RNN</a></br> <a href="/2016/09/20/%E8%BD%BB%E9%87%8F%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84.html">轻量应用服务器架构</a></br> <a href="/machinelearning/2016/08/16/CRF.html">CRF 笔记</a></br> <a href="/machinelearning/2016/08/16/PaperReadingNote.html">论文阅读笔记</a></br> <a href="/machinelearning/2016/04/03/EnsembleLearningMethods.html">Ensemble Learning Methods</a></br> <a href="/naturallanguageprocessing/2016/04/02/pLSA.html">Probability Latent Semantic Analysis</a></br> <a href="/machinelearning/2016/04/02/SVM.html">Support Vector Machine</a></br> <a href="/machinelearning/2016/04/02/SVD.html">SVD</a></br> <a href="/machinelearning/2016/04/02/RandomForests.html">Random Forest</a></br> <a href="/machinelearning/2016/04/02/HMM.html">HMM</a></br> <a href="/machinelearning/2016/04/02/ESL_Notes.html">ESL Notes</a></br> <a href="/algorithm/2016/04/02/DP.html">Dynamic Programming</a></br> <a href="/algorithm/2016/04/02/Bit.html">Bit Manupulation</a></br> </div> </article> <div class="ds-thread" data-thread-key="/machinelearning/2016/12/02/RNN" data-title="RNN" data-url="//machinelearning/2016/12/02/RNN.html" style='width:666px;margin:0px auto'></div> <!-- 多说评论框 end --> <!-- 多说公共JS代码 start (一个网页只需插入一次) --> <script type="text/javascript"> var duoshuoQuery = {short_name:"aron"}; (function() { var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); })(); </script> <!-- 多说公共JS代码 end --> <div class="back"> <a href="/">Back</a> </div> </main> </body> </html>